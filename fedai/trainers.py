# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_trainers.ipynb.ipynb.

# %% auto 0
__all__ = ['LLMTrainer']

# %% ../nbs/03_trainers.ipynb.ipynb 21
class LLMTrainer(Trainer):
    def __init__(
        self,
        client
    ) -> None:        
        super().__init__(client)
        
        self.client.train_iterator = iter(self.client.train_loader)
        self.client.model.generation_config.pad_token_id = self.client.tokenizer.pad_token_id
        self.data_key, self.label_key = 'input_ids', 'labels'

# %% ../nbs/03_trainers.ipynb.ipynb 22
@patch
def get_batch(self: LLMTrainer, batch):  # noqa: F811
    return {
                'input_ids': batch['input_ids'].to(self.device),
                'labels': batch['labels'].to(self.device),
                'attention_mask': batch['attention_mask'].to(self.device) 
            }
    

# %% ../nbs/03_trainers.ipynb.ipynb 23
@patch
def _forward(self: LLMTrainer, batch):
    outputs = self.client.model(**batch)
    loss = self.client.criterion(outputs)
    return loss, outputs.logits

# %% ../nbs/03_trainers.ipynb.ipynb 26
@patch
def test_generate(self: LLMTrainer) -> float:
    # print("****************************************")
    # print(f'Inside the test_generate () function of client {self.client.id}')

    lst_metrics = []
    self.client.model = self.client.model.to(self.device)
    self.client.model.eval()
    
    progress_bar_eval = tqdm(range(len(self.client.test_loader_genr)))

    with torch.no_grad():
        for batch in self.client.test_loader_genr:

            batch = self.get_batch(batch)

            output_ids = self.client.model.generate(
                input_ids=batch['input_ids'],
                attention_mask=batch['attention_mask'],
                max_new_tokens=self.cfg.max_new_tokens,
                num_beams=self.cfg.num_beams,
            )

            generated_ids = output_ids[:, len(batch['input_ids'][0]):] 
            metrics = self.test_metrics.compute(y_pred= generated_ids,
                                                y_true= batch['labels'],
                                                tokenizer= self.client.tokenizer)
    
            lst_metrics.append(metrics)

            # print(f"Client {self.client.id}'s Batch test metrics are : {metrics}")
            progress_bar_eval.update(1)

    # print("****************************************")
    epoch_metrics = {k: sum([m[k] for m in lst_metrics]) / len(lst_metrics) for k in lst_metrics[0].keys()}

    return epoch_metrics

