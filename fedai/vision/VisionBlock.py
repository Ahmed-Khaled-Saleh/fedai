"""Fill in a module description here"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/04_vision.VisionBlock.ipynb.

# %% auto 0
__all__ = ['VisionBlock']

# %% ../../nbs/04_vision.VisionBlock.ipynb 3
import numpy as np
import os
import sys
import random
import gc
import h5py
import torch
import torchvision
import torch.nn as nn
import gdown
import zipfile
from sklearn.model_selection import train_test_split
import ujson
import torchvision.transforms as transforms
from fastcore.utils import *
from .downloader import *

# %% ../../nbs/04_vision.VisionBlock.ipynb 4
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)

# %% ../../nbs/04_vision.VisionBlock.ipynb 8
class VisionBlock(torch.utils.data.Dataset):
    def __init__(self, cfg, id, train= True, download= True):
        self.cfg = cfg
        self.config_path = os.path.join(self.cfg.data.data_dir, self.cfg.data.name , "config.json")
        self.train_path = os.path.join(self.cfg.data.data_dir, self.cfg.data.name , "train")
        self.test_path = os.path.join(self.cfg.data.data_dir, self.cfg.data.name, "test")
        self.train = train
        self.id = id
        self.download_data()
        self.data = self.load_client_data()

    def url_mapper(self):
        k = "train" if self.train else "test"
        
        mapping = {
            "cifar10_hetro_30": 
                {"train": "https://drive.google.com/file/d/1Qq73WrxtlV3Wdg_USWY8inDb_R7reQcc/view?usp=sharing",
                 "test": "https://drive.google.com/file/d/1LDvB28hcWZOPQX_j0GbaCWKWe2Hd-0HN/view?usp=sharing",
                "zipname": f"cifar10_hetro_{k}_30.zip"
                 
                },

            "cifar10_20":
                {"train": "https://drive.google.com/file/d/14NBQaoW8etKzJ70Jf7BuANkR8MsN-j2Q/view?usp=sharing",
                 "test": "https://drive.google.com/file/d/1H1_QDLVXfipwauLEA8RJy1vfq4X8V9je/view?usp=sharing",
                 "zipname": f"cifar10_{k}_20.zip"
                },

            "mnist_rotated_40":
                {"train": "https://drive.google.com/file/d/1BtLqzHyeM6zSHpI_V9CVvERRH4yhsGKW/view?usp=sharing",
                 "test": "https://drive.google.com/file/d/1hDbHxlLZbCIhQHgfn-lXp6dCFKQT6MlK/view?usp=sharing",
                "zipname": f"mnist_rotated_{k}_40.zip"
                },

            "mnist_rotated_batched_40":
                {"train": "https://drive.google.com/file/d/10r4ZHFh4RaKTEPkC_x50e48A8gLS76d8/view?usp=sharing",
                 "test": "https://drive.google.com/file/d/1GeXdLUzaNlEoa5ki26ISUuLJJcoUjf53/view?usp=sharing",
                "zipname": f"mnist_rotated_batched_{k}_40.zip"
                }
                
            }
        if self.cfg.data.name not in mapping:
            raise ValueError(f"Dataset {self.cfg.data.name} not found in url mapping.")
        
        return mapping[self.cfg.data.name][k], mapping[self.cfg.data.name]['zipname']


    def download_data(self):
        
        url, zipname = self.url_mapper()
        if os.path.exists(os.path.join(self.cfg.data.data_dir, self.cfg.data.name, zipname)):
            return
        else:
            os.makedirs(os.path.join(self.cfg.data.data_dir, self.cfg.data.name), exist_ok= True)
               
        output = os.path.join(self.cfg.data.data_dir, self.cfg.data.name, zipname)
        gdown.download(url=url, output=output, fuzzy=True)

        with zipfile.ZipFile(output, 'r') as zip_ref:
            zip_ref.extractall(f'{self.train_path}' if self.train else f'{self.test_path}')

        print(f'Data downloaded and extracted to {self.train_path if self.train else self.test_path}')

    def tensorify(self, data):
        X = torch.tensor(data['x'], dtype= torch.float32)
        y = torch.tensor(data['y'], dtype= torch.int64)
        return {'x': X, 'y': y}

    def load_client_data(self):
        path, dir = (self.train_path, 'train') if self.train else (self.test_path, 'test')
        print(self.id)
        if self.id < 10:
            id = f'0000{self.id}'
        else:
            id = f'000{self.id}'

        with h5py.File(os.path.join(path, f'f_{id}'), 'r') as hf_file:
            x = hf_file['x'][:]
            y = hf_file['y'][:]
        return self.tensorify({'x': x, 'y': y})

    def __getitem__(self, idx):
        x = self.data['x'][idx]
        y = self.data['y'][idx]
        return {'x': x, 'y': y}

    def __len__(self):
        return len(self.data['y'])
