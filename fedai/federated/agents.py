"""The core abstraction for different FL Agents/Clients."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/02_federated.agents.ipynb.

# %% auto 0
__all__ = ['AgentRole', 'Agent', 'FLAgent', 'PeftAgent', 'PadgAgent', 'AgentMira']

# %% ../../nbs/02_federated.agents.ipynb 3
from fastcore.utils import *
import os
import json
from collections import defaultdict,OrderedDict
from copy import deepcopy
from enum import Enum
import torch
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
from peft import *
from ..trainers import *
from ..utils import *
from ..data.core import LLMDataCollator
from transformers import AutoTokenizer
from omegaconf.dictconfig import DictConfig
import numpy as np
np.random.seed(42)
torch.manual_seed(42)

# %% ../../nbs/02_federated.agents.ipynb 4
class AgentRole(Enum):
    SERVER = 1
    CLIENT = 2
    MARL = 3

# %% ../../nbs/02_federated.agents.ipynb 7
class Agent:
    def __init__(self,
                 id,
                 cfg,
                 state= None,
                 role= AgentRole.CLIENT):
        
        self.id = id # each agent has a unique id
        self.cfg = cfg # contains all the configurations needed for the agent/trainer.
        self.state = state # A dictionary containing the state of the agent
        self.role = role # either a client or a server

# %% ../../nbs/02_federated.agents.ipynb 8
@patch
def init_agent(self: Agent):
    # Initialize the state of the agent. In FL Agent, this means making any adjustments to the model/optimizer/state_dict/...etc
    raise NotImplementedError

# %% ../../nbs/02_federated.agents.ipynb 9
@patch
def communicate(self: Agent, msg):
    raise NotImplementedError

# %% ../../nbs/02_federated.agents.ipynb 10
@patch
def update_state(self: Agent):
    raise NotImplementedError

# %% ../../nbs/02_federated.agents.ipynb 11
@patch
def save_state(self: Agent):
    # save the state of the agent to a file on disk (id, model, optimizer, loss_fn).
    raise NotImplementedError

# %% ../../nbs/02_federated.agents.ipynb 12
@patch
def clear_model(self: Agent):
    self.model = None

# %% ../../nbs/02_federated.agents.ipynb 19
class FLAgent(Agent):
    # A Federated Learning Agent implementing `FedAVG`.
    def __init__(self,
                 id, # the id of the agent
                 cfg, # the configuration of the agent.
                 state= None, # the state of the agent (model, optimizer, loss_fn), etc.
                 role= AgentRole.CLIENT, # the role of the agent (client or server)
                 block= None): # The data block (local data of the FL Agent).
                 
        super().__init__(id, cfg, state, role)
        if block:
            self.train_ds, self.test_ds = block[0], block[1]
        
        if self.state :
            for key, value in self.state.items():
                setattr(self, key, value)
            self.init_agent()

        # self.__repre__ = self.__str__()

# %% ../../nbs/02_federated.agents.ipynb 23
@patch
def __str__(self: FLAgent) -> str:
    return f'''{self.__class__.__name__}: {self.__class__.__name__}
    Index : {self.id}
    Model: {self.model.__class__.__name__}
    Criterion: {self.criterion.__class__.__name__}
    Optimizer: {self.optimizer.__class__.__name__}'''


# %% ../../nbs/02_federated.agents.ipynb 24
@patch
def init_agent(self: FLAgent):  # noqa: F811
    self.optimizer = get_class('torch.optim', self.cfg.optimizer.name)(self.model.parameters(),  # noqa: F405
                                                                                lr= self.cfg.lr)

# %% ../../nbs/02_federated.agents.ipynb 25
@patch
def clear_model(self: FLAgent):
    self.model = None if hasattr(self, 'model') else None

# %% ../../nbs/02_federated.agents.ipynb 26
@patch
def save_state(self: FLAgent, state_dict, comm_round, id):  # noqa: F811
    # save the model to self.cfg.save_dir/comm_round/f"local_output_{id}"/pytorch_model.bin
    
    model_path = os.path.join(self.cfg.save_dir, 
                              str(comm_round),
                              f"local_output_{id}")

    os.makedirs(model_path, exist_ok=True)
    torch.save(state_dict, 
               os.path.join(model_path, 
                            "pytorch_model.pth"))

    if self.role == AgentRole.CLIENT:
        save_space(self)


# %% ../../nbs/02_federated.agents.ipynb 29
@patch
def communicate(self: Agent, another_agent: Agent, comm_round):  # noqa: F811
    if self.role == AgentRole.CLIENT:
        self.save_state(self.model.state_dict(), comm_round, self.id)

# %% ../../nbs/02_federated.agents.ipynb 30
@patch
def aggregate(self: FLAgent, lst_active_ids, comm_round, len_clients_ds, one_model= False):
    # load the models of the agents in lst_active_ids and `FedAvg` them. At the end, save the aggregated model to the disk.
        
    for i, id in enumerate(lst_active_ids):
        model_path = os.path.join(self.cfg.save_dir, 
                                   str(comm_round),
                                   f"local_output_{id}",
                                   "pytorch_model.pth")
        client_state_dict = torch.load(model_path, map_location='cpu')

        if i == 0:
            client_avg = {
                key: torch.zeros_like(value) 
                for key, value in client_state_dict.items()
            }
        
        weight = len_clients_ds[i] / sum(len_clients_ds)

        for key in client_state_dict.keys():
            client_avg[key].data += weight * client_state_dict[key].data

    for key in client_avg.keys():
        client_avg[key].data /= len(lst_active_ids)

    # Either we are aggregating and distributing to all clients or just for active clients (personalization/MTL)
    all_ids = list(range(self.cfg.num_clients))
    looped_ids = lst_active_ids if not one_model else all_ids
    
    for id in looped_ids:
        model_path = os.path.join(self.cfg.save_dir, 
                                  str(comm_round),
                                  f"local_output_{id}",
                                  "pytorch_model.pth")
        self.save_state(client_avg, comm_round, id)
    

# %% ../../nbs/02_federated.agents.ipynb 35
class PeftAgent(FLAgent):
    def __init__(self,
                 cfg,
                 block,
                 id,
                 state= None,
                 role= "client",
                 **adapter_settings):
        super().__init__(cfg, block, id, state, role)


# %% ../../nbs/02_federated.agents.ipynb 36
@patch
def peftify(self: PeftAgent):
    # extract only the adapter's parameters from the model and store them in a dictionary
    self.params_dict_old = deepcopy(
        OrderedDict((name, param.detach()) for name, param in self.model.named_parameters() if
                    "default" in name))
    
    self.params_dict_new = deepcopy(self.params_dict_old)
    
    self.model.state_dict = (
        lambda instance, *_, **__: get_peft_model_state_dict(  # noqa: F405
            instance, self.params_dict_new, "default"
        )
    ).__get__(self.model, type(self.model))

# %% ../../nbs/02_federated.agents.ipynb 37
@patch 
def init_agent(self: PeftAgent):  # noqa: F811
    super().init_agent()
    self.peftify()


# %% ../../nbs/02_federated.agents.ipynb 38
@patch
def save_state_(self: PeftAgent, epoch, local_dataset_len_dict, previously_selected_clients_set):  # noqa: F811
    # save the new adapter weights to disk
    self.save_state(epoch)

    local_dataset_len_dict[self.id] = len(self.block)
    older_adapter_weight = get_peft_model_state_dict(self.model, self.params_dict_old, "default")  # noqa: F405
    set_peft_model_state_dict(self.model, older_adapter_weight, "default")  # noqa: F405
    previously_selected_clients_set = previously_selected_clients_set | set({self.id})
    last_client_id = self.id

    return self.model, local_dataset_len_dict, previously_selected_clients_set, last_client_id

# %% ../../nbs/02_federated.agents.ipynb 41
class PadgAgent(FLAgent):
    def __init__(self,
                 id, # the id of the agent
                 cfg, # the configuration of the agent.
                 state= None, # the state of the agent (model, optimizer, loss_fn), etc.
                 role= AgentRole.CLIENT, # the role of the agent (client or server)
                 block= None):
        super().__init__(id, cfg, state, role, block)

        if role == AgentRole.SERVER:
            self.connections = torch.from_numpy(generate_graph(self.cfg.num_clients))  # noqa: F405


# %% ../../nbs/02_federated.agents.ipynb 42
@patch
def apply_constraints(self: PadgAgent, 
                      graph, # (np.ndarray): The input matrix.
                      symmetrize=True, # (bool): If True, makes the matrix symmetric.
                      normalize=True, # (bool): If True, normalizes the matrix symmetrically.
                      threshold= 0, # (float or None): If provided, sets values below this threshold to 0.
                      diag_fill= 0): # (float or None): If provided, fills the diagonal with this value.
    

    # Symmetrize the matrix
    if symmetrize:
        graph = (graph + graph.T) / 2

    # Apply threshold to ensure non-negativity
    if threshold is not None:
        graph = torch.where(graph > threshold, graph, 0)

    # Normalize the matrix symmetrically
    if normalize:
        row_sums = graph.sum(axis=1, keepdims=True)
        col_sums = graph.sum(axis=0, keepdims=True)
        norm_factor = torch.sqrt(row_sums @ col_sums)  # Symmetric normalization factor
        graph = torch.divide(graph, norm_factor, where=norm_factor != 0)

    # Fill the diagonal
    if diag_fill is not None:
        torch.fill_diagonal(graph, diag_fill)

    return graph


# %% ../../nbs/02_federated.agents.ipynb 46
@patch
def compute_probs(self: PadgAgent,
                  batch_size=32, # batch_size (int): Batch size for evaluation.
                  return_log_probs=True): # return_log_probs (bool): If True, return log-probabilities; otherwise, return probabilities.
    
    # Computes probabilities or log-probabilities across the entire dataset for a given model.
    # Ensure model is in evaluation mode
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    self.model.to(device)
    self.model.eval()
    
    # Create DataLoader for the dataset
    dataloader = DataLoader(self.train_ds, batch_size=batch_size, shuffle=False)
    
    all_probs = []  # To store probabilities or log-probabilities for all batches
    
    with torch.no_grad():  # Disable gradient computation
        for batch in dataloader:  # Assuming dataset returns (inputs, labels)
            print(batch['x'])
            inputs = batch['x'].to(device)  # Move to model's device
            
            # Get logits from the model
            logits = self.model(inputs)
            
            if return_log_probs:
                # Convert logits to log-probabilities
                batch_log_probs = F.log_softmax(logits, dim=-1)
                all_probs.append(batch_log_probs)
            else:
                # Convert logits to probabilities
                batch_probs = F.softmax(logits, dim=-1)
                all_probs.append(batch_probs)
    
    self.model.to('cpu')
    # Concatenate all batch probabilities/log-probabilities
    return torch.cat(all_probs, dim=0)


# %% ../../nbs/02_federated.agents.ipynb 48
@patch
def aggregate(self: PadgAgent, lst_active_ids, comm_round, len_clients_ds, one_model= False):
    
    visited = []
    for i, id in enumerate(lst_active_ids):

        neighbour_ids = torch.where(self.connections[id] != float(0))[0]

        model_path = os.path.join(self.cfg.save_dir, 
                                   str(comm_round),
                                   f"local_output_{id}",
                                   "pytorch_model.pth")
        client_state_dict = torch.load(model_path, map_location='cpu')
        self.model.load_state_dict(client_state_dict)
        
        neighbours_sum = {
            key: torch.zeros_like(value) 
            for key, value in client_state_dict.items()
        }
            
        probs_1 = self.compute_probs(batch_size=32, return_log_probs=True)
        
        for other_id in neighbour_ids:

            if (other_id, id) in visited:
                continue
            other_model_path = os.path.join(self.cfg.save_dir, 
                                    str(comm_round),
                                    f"local_output_{other_id}",
                                    "pytorch_model.pth")
            
            other_client_state_dict = torch.load(other_model_path, map_location='cpu')
            self.model.load_state_dict(other_client_state_dict)
            
            probs_2 = self.compute_probs(batch_size=32, return_log_probs=False)

            kl_div = F.kl_div(probs_1, probs_2, reduction= 'batchmean').to('cpu')
            self.connections[id][other_id] -= self.cfg.server_lr * self.cfg.lambda_ * kl_div

            # apply constraints to the KL divergence
            self.connections[id][other_id] = self.apply_constraints(self.connections[id][other_id])
            self.connections[id][other_id] = self.connections[other_id][id]

            visited.append((id, other_id))
            visited.append((other_id, id))
            
        for other_id in neighbour_ids:
            other_model_path = os.path.join(self.cfg.save_dir, 
                                    str(comm_round),
                                    f"local_output_{other_id}",
                                    "pytorch_model.pth")
            other_client_state_dict = torch.load(other_model_path, map_location='cpu')

            weight = self.connections[id][other_id]
            for key in other_client_state_dict.keys():
                neighbours_sum[key].data += weight * other_client_state_dict[key].data

        # for key in neighbours_sum.keys():
            # neighbours_sum[key].data /= len(neighbour_ids)

        for key in client_state_dict.keys():
            client_state_dict[key].data = self.cfg.beta * client_state_dict[key].data + (1 - self.cfg.beta) * neighbours_sum[key].data

    
        # save the updated model to the disk
        self.save_state(client_state_dict, comm_round + 1, id)
        

# %% ../../nbs/02_federated.agents.ipynb 53
class AgentMira(FLAgent):
    def __init__(self,
                 data_dict: dict,
                 model: torch.nn.Module,
                 criterion,
                 optimizer: torch.optim.Optimizer,
                 id: int,
                 gen_data_dict: dict,
                 tokenizer: AutoTokenizer,
                 collat_fn: LLMDataCollator,
                 cfg: DictConfig) -> None:
            
        super().__init__(data_dict, model, criterion, optimizer, id)
        
        self.train_ds_genr = gen_data_dict['train']
        self.test_ds_genr = gen_data_dict['test']
        self.tokenizer = tokenizer
        self.collat_fn = collat_fn
        self.cfg = cfg 
