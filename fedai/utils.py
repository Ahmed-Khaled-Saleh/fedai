"""Fill in a module description here"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/05_utils.ipynb.ipynb.

# %% auto 0
__all__ = ['get_class', 'get_server', 'load_config', 'save_space', 'prepare_dl', 'LazyList']

# %% ../nbs/05_utils.ipynb.ipynb 3
import os
from fastcore.utils import *  # noqa: F403
from torch.utils.data import DataLoader
import yaml
import torch
from .data import * # noqa: F403
from .vision.models import * # noqa: F403


# %% ../nbs/05_utils.ipynb.ipynb 4
import importlib
def get_class(module_name, class_name):
    module = importlib.import_module(module_name)
    return getattr(module, class_name)

# %% ../nbs/05_utils.ipynb.ipynb 5
def get_server(cfg, lst_data_dict, model, holdout_ds, **kwargs):
    Server = get_class('fedai.servers', f'Server_{cfg.name}')
    client_class = get_class('fedai.clients', f'Client_{cfg.name}')
    return Server(cfg, lst_data_dict, model, holdout_ds, client_class, **kwargs)

# %% ../nbs/05_utils.ipynb.ipynb 6
def load_config(file_path):
    with open(file_path, 'r') as file:
        return yaml.safe_load(file)

# %% ../nbs/05_utils.ipynb.ipynb 7
def save_space(client) -> None:
    client.clear_model()
    del client.optimizer
    del client
    import gc
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

# %% ../nbs/05_utils.ipynb.ipynb 9
def prepare_dl(cfg, ds, shuffle=True, collate_fn=None):
    return DataLoader(
        ds,
        batch_size= cfg.data.batch_size,
        shuffle= shuffle,
        collate_fn= collate_fn     
    )

# %% ../nbs/05_utils.ipynb.ipynb 18
class LazyList:
    def __init__(self, server, client_cls):
        self.server = server
        self.client_cls = client_cls
        self.client_cache = {}  # Cache to store initialized clients

    def clear_cache(self):
        # Clear the cache to free memory if needed
        self.client_cache = {}


# %% ../nbs/05_utils.ipynb.ipynb 19
@patch
def __getitem__(self: LazyList, idx):
    # Check if the client is already instantiated
    if idx not in self.client_cache:
        # Instantiate the client and store it in the cache
        self.client_cache[idx] = self.client_cls(
            data_dict= self.server.lst_data_dict[idx],
            model= None, #deepcopy(self.server.model),
            criterion= self.server.criterion,
            optimizer= None, #get_class('torch.optim', self.server.cfg.optimizer)(self.server.model.parameters(), lr= self.server.cfg.lr),
            idx= idx,
            gen_data_dict= self.server.lst_gen_data_dict[idx],
            tokenizer= self.server.tokenizer,
            collat_fn= self.server.collat_fn,
            cfg= self.server.cfg
        )
    return self.client_cache[idx]
