{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design Choices:\n",
    "- Config files managment : **Hydra**.\n",
    "- Datasets: HuggingFace's **Datasets** library.\n",
    "- Working with Dimensions: **Einops**.\n",
    "- Data Validation : **Pydantic**.\n",
    "- Logging: **loguru**.\n",
    "- CLI table pretty prints: **python-tabulate**.\n",
    "- **Cython** for performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation Suite:\n",
    "- Pytroch, Transformers, Peft.\n",
    "- Hydra, einops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def say_hello(to):\n",
    "    \"Say hello to somebody\"\n",
    "    return f'Hello {to}!'\n",
    "def get_cfg():\n",
    "    from omegaconf import DictConfig, OmegaConf\n",
    "    import argparse\n",
    "    import os\n",
    "    args = dict()\n",
    "    args['dataset'] = 'dolly'\n",
    "    args['model'] = \"openai-community/gpt2\"\n",
    "    args['max_length'] = 1022\n",
    "    args['num_clients'] = 80\n",
    "    args['iid'] = \"dir0.5\"\n",
    "    args['batch_size'] = 1\n",
    "    args['dataset_subsample'] = 1.0\n",
    "    args['eval_metric'] = 'loss'\n",
    "    args['log_root'] = 'logs'\n",
    "    args['save_dir'] = 'checkpoints'\n",
    "    args['lora_alpha'] = 8\n",
    "    args['lora_dropout'] = 0.05\n",
    "    args['r'] = 32\n",
    "    args['target_modules'] = ['c_attn']\n",
    "    args['lr'] = 5e-5\n",
    "    args['optimizer'] = 'Adam'\n",
    "    args = argparse.Namespace(**args)\n",
    "    args.name = 'mira'\n",
    "    args.device = 0\n",
    "    args.bias_sampling = False\n",
    "    args.num_clients_per_task = int(args.num_clients/8)\n",
    "    args.use_prompts= True\n",
    "    args.rounds = 40\n",
    "    args.m = 0.05\n",
    "    cfg = OmegaConf.create(vars(args))\n",
    "    return cfg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "class simple_model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_model, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(10, 5)\n",
    "        self.fc2 = torch.nn.Linear(5, 2)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
