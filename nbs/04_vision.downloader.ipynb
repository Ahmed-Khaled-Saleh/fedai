{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data\n",
    "\n",
    "> Fill in a module description here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp vision.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from fedai.data.downloader import *\n",
    "from fedai.utils import *\n",
    "from fastcore.utils import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VisionDownloader(BaseDownloader):  # noqa: F405\n",
    "    def __init__(self, cfg, transform=None):\n",
    "        self.transform_norm_mapping = {\n",
    "            \"CIFAR10\": ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            \"CIFAR100\": ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            \"MNIST\": ((0.5,), (0.5,)),\n",
    "            \"FashionMNIST\": ((0.5,), (0.5,)),\n",
    "            \"EMNIST\": ((0.5,), (0.5,)),\n",
    "        }\n",
    "        if not transform:\n",
    "            self.transform = transforms.Compose(\n",
    "                [transforms.ToTensor(), \n",
    "                transforms.Normalize(self.transform_norm_mapping[cfg.data.name][0],\n",
    "                                    self.transform_norm_mapping[cfg.data.name][1])])\n",
    "\n",
    "        else:\n",
    "            self.transform = transform\n",
    "        super().__init__(cfg)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def load_data(self: VisionDownloader):\n",
    "    if not os.path.exists(self.cfg.data.dir_path):\n",
    "        os.makedirs(self.cfg.data.dir_path)\n",
    "    \n",
    "    ds_class = get_class(\"torchvision.datasets\", self.cfg.data.name)  # noqa: F405\n",
    "    # Setup directory for train/test data\n",
    "    if self.check():\n",
    "        return\n",
    "    \n",
    "    trainset = ds_class(\n",
    "        root=os.path.join(self.cfg.data.dir_path, self.cfg.data.name, \"rawdata\"), train=True, download=True, transform=self.transform)\n",
    "    testset = ds_class(\n",
    "        root=os.path.join(self.cfg.data.dir_path, self.cfg.data.name, \"rawdata\"), train=False, download=True, transform=self.transform)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=len(trainset.data), shuffle=False)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=len(testset.data), shuffle=False)\n",
    "\n",
    "    for _, train_data in enumerate(trainloader, 0):\n",
    "        trainset.data, trainset.targets = train_data\n",
    "    for _, test_data in enumerate(testloader, 0):\n",
    "        testset.data, testset.targets = test_data\n",
    "\n",
    "    dataset_image = []\n",
    "    dataset_label = []\n",
    "\n",
    "    dataset_image.extend(trainset.data.cpu().detach().numpy())\n",
    "    dataset_image.extend(testset.data.cpu().detach().numpy())\n",
    "    dataset_label.extend(trainset.targets.cpu().detach().numpy())\n",
    "    dataset_label.extend(testset.targets.cpu().detach().numpy())\n",
    "    dataset_image = np.array(dataset_image)\n",
    "    dataset_label = np.array(dataset_label)\n",
    "\n",
    "    num_classes = len(set(dataset_label))\n",
    "    print(f'Number of classes: {num_classes}')\n",
    "\n",
    "    return dataset_image, dataset_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
