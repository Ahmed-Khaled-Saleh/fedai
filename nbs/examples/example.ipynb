{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.datasets import ImageFolder\n",
    "# from torchvision import transforms\n",
    "# # the training transforms\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# train_transforms = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(300, scale=(0.8, 1.0)),  # Random crop + resize\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),  # Flip with 50% probability\n",
    "#     transforms.RandomRotation(10),  # Rotate within Â±10 degrees\n",
    "#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color augmentation\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalize to [-1, 1]\n",
    "# ])\n",
    "\n",
    "\n",
    "# # the validation transforms\n",
    "# valid_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(\n",
    "#         mean=[0.5, 0.5, 0.5],\n",
    "#         std=[0.5, 0.5, 0.5]\n",
    "#     )\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import transforms, datasets\n",
    "# import torch\n",
    "# train_dataset = datasets.ImageFolder(root=\"./RF data\", transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, Subset\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Assume dataset has a .targets attribute that holds class labels\n",
    "# class_to_indices = defaultdict(list)\n",
    "\n",
    "# # Group dataset indices by class\n",
    "# for idx, (_, label) in enumerate(train_dataset):\n",
    "#     class_to_indices[label].append(idx)\n",
    "\n",
    "# # Now class_to_indices[label] contains all indices of images belonging to `label`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_splits = {label: Subset(train_dataset, indices) for label, indices in class_to_indices.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import random_split\n",
    "\n",
    "# train_ratio = 0.8\n",
    "\n",
    "# train_subsets = {}\n",
    "# test_subsets = {}\n",
    "\n",
    "# for label, subset in class_splits.items():\n",
    "#     subset_size = len(subset)\n",
    "#     train_size = int(train_ratio * subset_size)\n",
    "#     test_size = subset_size - train_size\n",
    "\n",
    "#     train_subset, test_subset = random_split(subset, [train_size, test_size])\n",
    "    \n",
    "#     train_subsets[label] = train_subset\n",
    "#     test_subsets[label] = test_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# class DictDataset(Dataset):\n",
    "#     def __init__(self, subset):\n",
    "#         self.subset = subset  # A Subset of the original dataset\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.subset)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x, y = self.subset[idx]  # Extract image and label\n",
    "#         return {\"x\": x, \"y\": y}  # Return as a dictionary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DictDataset(train_subsets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = np.random.randint(0, len(train_dataset), 1)[0]\n",
    "# image = train_dataset[r][0]\n",
    "# print(image.shape)\n",
    "# # show image\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# plt.imshow(image.numpy().reshape(224, 224, 3))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the numeric  values of all the labels in the dataset\n",
    "# labels = [train_dataset[i][1] for i in range(len(train_dataset))]\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = train_dataset[r][1]\n",
    "# label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load efficnetnetv3\n",
    "# import torch\n",
    "# import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.efficientnet_b0(pretrained=False)  # Load EfficientNet-B0 without pretraining\n",
    "# num_classes = 20 \n",
    "# model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "# model = model.eval()\n",
    "# output = model(image.unsqueeze(0))\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = torch.argmax(output, dim=1)\n",
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('Encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from community import community_louvain\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import networkx as nx\n",
    "\n",
    "# # load the karate club graph\n",
    "# G = nx.karate_club_graph()\n",
    "\n",
    "# # compute the best partition\n",
    "# partition = community_louvain.best_partition(G)\n",
    "\n",
    "# # draw the graph\n",
    "# pos = nx.spring_layout(G)\n",
    "# # color the nodes according to their partition\n",
    "# cmap = cm.get_cmap('viridis', max(partition.values()) + 1)\n",
    "# nx.draw_networkx_nodes(G, pos, partition.keys(), node_size=40,\n",
    "#                        cmap=cmap, node_color=list(partition.values()))\n",
    "# nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "# # save as pdf\n",
    "# plt.savefig(\"outcome.pdf\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from fedai.FLearner import *  # noqa: F403\n",
    "# from fedai.learner_utils import *  # noqa: F403\n",
    "# from fedai.utils import * # noqa: F403\n",
    "# from omegaconf import OmegaConf\n",
    "\n",
    "# def cfg_fn(f):\n",
    "#     cfg = load_config(f)  # noqa: F405\n",
    "#     cfg = OmegaConf.create(cfg)\n",
    "#     return cfg\n",
    "# cfg = cfg_fn('cfg.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# args = argparse.Namespace(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fedai.federated.agents import *  # noqa: F403\n",
    "# import torch\n",
    "# client = client_fn(FLAgent, cfg, id= 0, latest_round={}, loss_fn=torch.nn.CrossEntropyLoss())  # noqa: F405\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fedai.FLearner import * # noqa: F403\n",
    "\n",
    "# flearner = FLearner(cfg, client_fn, client_cls= PadgAgent)  # noqa: F405\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flearner.run_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
