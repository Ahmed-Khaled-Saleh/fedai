project_name: example_project
random_seed: 42

# Federated learning configuration
num_clients: 20
n_rounds: 10 
m: 0.1 
local_epochs: 2 # number of local epochs
lr: 0.01 
agg: one_model # aggregation method, either 'one_model' or 'diff'

# save and log directories
save_dir : models
res_dir: results
log_dir: logs

# metrics
training_metrics: [accuracy]
test_metrics: [accuracy]

# Data configuration
data:
  data_dir: data
  modality: [Vision]
  batch_size: 10
  name: MNIST
  niid: false
  balance: false
  partitioner: DirPartitioner
  alpha: 0.1
  train_ratio: 0.75
  num_classes: 2

# Model configuration
model:
  name: MLP
  dim_in: 784
  dim_hidden: 128
  dim_out: 10
  vocab_size: 1000
  embed_size: 128
  hidden_size: 128
  num_layers: 1
  grad_norm_clip: 1.0

  peft:
    r: 16
    lora_alpha: 32
    lora_dropout: 0.05
    target_modules: ['c_attn','c_proj']


optimizer:
  name: Adam
  lr: 0.001
  weight_decay: 0.0