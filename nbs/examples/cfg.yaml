project_name: example_project
random_seed: 42

# Federated learning configuration
num_clients: 20
n_rounds: 10 
m: 0.1 
local_epochs: 2 # number of local epochs
lr: 0.01 
agg: one_model # aggregation method, either 'one_model' or 'diff'

# FLearner arguments
client_selector: BaseClientSelector
client_cls: FLAgent
loss_fn: CrossEntropyLoss
writer: WandbWriter


# save and log directories
save_dir : models
res_dir: results
log_dir: logs

# metrics
training_metrics: [accuracy]
test_metrics: [accuracy]

# Data configuration
data:
  data_dir: data
  modality: [Vision]
  batch_size: 10
  name: MNIST
  niid: false
  balance: false
  partitioner: DirPartitioner
  alpha: 0.1
  train_ratio: 0.75
  num_classes: 2

# Model configuration
model:
  name: MLP
  dim_in: 784
  dim_hidden: 128
  dim_out: 10
  hidden_size: 128
  grad_norm_clip: 1.0



# optimzer configuration
optimizer:
  name: Adam
  weight_decay: 0.0