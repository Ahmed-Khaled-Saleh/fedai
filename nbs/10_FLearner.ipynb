{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLearner\n",
    "\n",
    "> Fill in a module description here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp FLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *  # noqa: F403"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo\n",
    "\n",
    "- Add the TextBlock and The TabularBlock.\n",
    "- Add loging using Loguru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "from fastcore.utils import * # type: ignore # noqa: F403\n",
    "from fedai.federated.agents import * # noqa: F403\n",
    "from fedai.learner_utils import * # type: ignore # noqa: F403\n",
    "from fedai.client_selector import *  # noqa: F403\n",
    "from fedai.core import get_cfg  # noqa: F401, F403\n",
    "from fedai.wandb_writer import *  # noqa: F403\n",
    "from torch import nn\n",
    "from omegaconf import OmegaConf\n",
    "import argparse\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def client_fn(client_cls, cfg, id, latest_round, t, loss_fn = None, optimizer = None):\n",
    "    \n",
    "    model = get_model(cfg)\n",
    "    criterion = get_criterion(loss_fn)\n",
    "\n",
    "    train_block = get_block(cfg, id)\n",
    "    test_block = get_block(cfg, id, train=False)    \n",
    "    \n",
    "    state = {'model': model, 'optimizer': None, 'criterion': criterion, 't': t}\n",
    "    \n",
    "    if t > 1:\n",
    "        state = load_state_from_disk(cfg, state, latest_round, id, t)  # noqa: F405\n",
    "    \n",
    "    state['optimizer'] = get_cls(\"torch.optim\", cfg.optimizer.name)(state['model'].parameters(), lr=cfg.lr)\n",
    "    \n",
    "    return client_cls(id, cfg, state, block= [train_block, test_block])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FLearner:\n",
    "    def __init__(self,\n",
    "                 cfg, # OmegaConf object\n",
    "                 client_fn, # a function that returns a client object\n",
    "                 client_selector= BaseClientSelector, # a client selection class represnting a client seleection algorithm # noqa: F405\n",
    "                 client_cls= FLAgent,  # noqa: F405\n",
    "                 loss_fn= torch.nn.CrossEntropyLoss,  # noqa: F405\n",
    "                 writer= WandbWriter): # a writer to write results to an expirement tracking tool # noqa: F405\n",
    "        \n",
    "        self.cfg = cfg\n",
    "        self.cfg.now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.cfg.save_dir = os.path.join(self.cfg.root_dir, self.cfg.now, self.cfg.save_dir)\n",
    "        self.cfg.log_dir = os.path.join(self.cfg.root_dir, self.cfg.now, self.cfg.log_dir)\n",
    "        self.cfg.res_dir = os.path.join(self.cfg.root_dir, self.cfg.now, self.cfg.res_dir)\n",
    "\n",
    "        self.client_fn = client_fn\n",
    "        \n",
    "        self.client_selector = client_selector(self.cfg)\n",
    "        self.client_cls = client_cls\n",
    "        self.loss_fn = loss_fn()\n",
    "        self.writer = writer(cfg)\n",
    "        self.server  = self.client_cls(cfg= self.cfg, block= None, id= -1, state= None, role= AgentRole.SERVER)  # noqa: F405\n",
    "        self.server.server_init(self.client_fn, self.client_selector, self.client_cls, self.loss_fn, self.writer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def run_simulation(self: FLearner):\n",
    "    self.server.runFL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(description='Run Federated Learning Simulation')\n",
    "#     parser.add_argument('--config', type=str, help='Path to the config file', required=True)\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     try:\n",
    "#         with open(args.config, 'r') as file:\n",
    "#             cfg = yaml.safe_load(file)\n",
    "#             cfg = OmegaConf.create(cfg)\n",
    "#     except:\n",
    "#         print(\"Invalid config file path\")\n",
    "    \n",
    "#     client_selector = get_cls(\"fedai.client_selector\", cfg.client_selector)\n",
    "#     client_cls = get_cls(\"fedai.federated.agents\", cfg.client_cls)\n",
    "#     loss_fn = get_cls(\"torch.nn\", cfg.loss_fn)\n",
    "#     writer = get_cls(\"fedai.wandb_writer\", cfg.writer)\n",
    "\n",
    "\n",
    "#     learner = FLearner(cfg, client_fn, client_selector, client_cls, loss_fn, writer)\n",
    "#     learner.run_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# @patch\n",
    "# def run_simulation(self: FLearner):\n",
    "#     res =  []\n",
    "#     all_ids = self.client_selector.select()\n",
    "    \n",
    "#     for t in range(1, self.cfg.n_rounds):\n",
    "#         lst_active_ids = all_ids[t]\n",
    "#         len_clients_ds = []\n",
    "#         round_res = []\n",
    "\n",
    "#         for id in lst_active_ids:\n",
    "#             client = self.client_fn(self.client_cls, self.cfg, id, self.latest_round, t, self.loss_fn)\n",
    "#             len_clients_ds.append(len(client.train_ds))\n",
    "            \n",
    "#             self.server.communicate(client) \n",
    "\n",
    "#             client_history = client.fit() \n",
    "#             round_res.append(client_history)\n",
    "#             res.append(round_res)\n",
    "\n",
    "#             client.communicate(self.server) \n",
    "#             self.latest_round[id] = t \n",
    "\n",
    "#         one_model = True if self.server.cfg.agg == 'one_model' else False\n",
    "#         self.server.aggregate(lst_active_ids, t, len_clients_ds, one_model= one_model) \n",
    "#         self.writer.write(round_res, t) \n",
    "        \n",
    "#     self.writer.save(res)\n",
    "#     self.writer.finish()\n",
    "\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev # type: ignore\n",
    "nbdev.nbdev_export() # type: ignore  # noqa: E702\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
