{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "\n",
    "> The core abstraction for different FL Agents/Clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp federated.agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "from fastcore.utils import *\n",
    "from fastcore.all import *\n",
    "import os\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import json\n",
    "from collections import defaultdict,OrderedDict\n",
    "from copy import deepcopy\n",
    "from enum import Enum\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from peft import *\n",
    "from community import community_louvain\n",
    "from fedai.utils import *\n",
    "from fedai.client_selector import *\n",
    "from fedai.optimizers import *\n",
    "from fedai.data.core import LLMDataCollator\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "from fedai.utils import *\n",
    "from fedai.metrics import *\n",
    "from transformers import AutoTokenizer\n",
    "from omegaconf.dictconfig import DictConfig\n",
    "import numpy as np\n",
    "import math\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AgentRole(Enum):\n",
    "    SERVER = 1\n",
    "    CLIENT = 2\n",
    "    MARL = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Agent\n",
    "\n",
    "An agent is an entity that has a state and exist in an environment. In the case of Federated learning (FL), the agent's state is defined as its own model, data, criterion, optimizer. FL Focuses on distributed model training across multiple clients (agents), each with its local data. Clients **collaborate** to improve a global or shared model while keeping their data private. Communication is often periodic (e.g., every few training rounds). On the other hand, Multi-agent RL systems (MARL) Involves multiple agents interacting with an environment to learn policies for specific tasks (e.g., navigation, resource allocation). Each agent has a state also, but the state represntation might differ slightly from that of an FL agent. The data is often not preloaded as in FL rather, it's collected from the environemnt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Agent:\n",
    "    def __init__(self,\n",
    "                 id,\n",
    "                 cfg,\n",
    "                 state= None,\n",
    "                 role= AgentRole.CLIENT):\n",
    "        \n",
    "        self.id = id # each agent has a unique id\n",
    "        self.cfg = cfg # contains all the configurations needed for the agent/trainer.\n",
    "        self.state = state # A dictionary containing the state of the agent\n",
    "        self.role = role # either a client or a server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def init_agent(self: Agent):\n",
    "    # Initialize the state of the agent. In FL Agent, this means making any adjustments to the model/optimizer/state_dict/...etc\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def communicate(self: Agent, msg):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def update_state(self: Agent):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def save_state(self: Agent):\n",
    "    # save the state of the agent to a file on disk (id, model, optimizer, loss_fn).\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def clear_model(self: Agent):\n",
    "    self.model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MARL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MARLAgent(Agent):\n",
    "    def _sense(self, state):\n",
    "        # sense the environment\n",
    "        self.state = state\n",
    "\n",
    "    def _decide(self):\n",
    "    # Compute the next action(s) based on the current state and observations.\n",
    "        pass\n",
    "\n",
    "    def _act(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FL Agent (FedAVG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FLAgent(Agent):\n",
    "    # A Federated Learning Agent implementing `FedAVG`.\n",
    "    def __init__(self,\n",
    "                 id, # the id of the agent\n",
    "                 cfg, # the configuration of the agent.\n",
    "                 state= None, # the state of the agent (model, optimizer, loss_fn), etc.\n",
    "                 role= AgentRole.CLIENT, # the role of the agent (client or server)\n",
    "                 block= None # The data block (local data of the FL Agent).\n",
    "                 ):  \n",
    "                 \n",
    "        super().__init__(id, cfg, state, role)\n",
    "\n",
    "        if self.role == AgentRole.CLIENT:\n",
    "            self.train_ds, self.test_ds = block[0], block[1]\n",
    "            \n",
    "            for key, value in self.state.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "            self.train_loader = prepare_dl(self.cfg, self.train_ds)  # noqa: F405\n",
    "            self.test_loader = prepare_dl(self.cfg, self.test_ds) # noqa: F405\n",
    "\n",
    "            self.training_metrics = Metrics(list(self.cfg.training_metrics))  # noqa: F405\n",
    "            self.test_metrics = Metrics(list(self.cfg.test_metrics))  # noqa: F405\n",
    "\n",
    "            self.data_key, self.label_key = 'x', 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "@patch\n",
    "def server_init(self: FLAgent, client_fn, client_selector, client_cls, loss_fn, writer):\n",
    "    self.client_fn = client_fn\n",
    "    self.client_selector = client_selector\n",
    "    self.client_cls = client_cls\n",
    "    self.loss_fn = loss_fn\n",
    "    self.writer = writer\n",
    "    self.latest_round = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since data blocks are already on the disk, and since RL agents don't have a preloaded data blocks, we don't include the data in the FL agent's state. Another ratioanle behind this decision is that, state should contain dynamic objects that change over the interaction of the agents and data blocks are static in the case of FL agents, unless you are doing FL-RL Agents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every client abstraction, whether it a base or any other type of federated client, it will initalize the training locally with a set of steps. This might include things like extracting the peft model out of the base model (in the case of LLMs clients). Also, it will terminate the local training with some steps, like saving the model state dictionary and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def runFL(self: FLAgent):\n",
    "    res =  []\n",
    "    all_ids = self.client_selector.select()\n",
    "    \n",
    "    for t in range(1, self.cfg.n_rounds + 1):\n",
    "        lst_active_ids = all_ids[t]\n",
    "        len_clients_ds = []\n",
    "        \n",
    "        train_res, test_res = self.evaluate(t)\n",
    "        train_df, test_df = self.writer.write(lst_active_ids, train_res, test_res, t) \n",
    "        res.append((train_df, test_df))\n",
    "        \n",
    "        for id in lst_active_ids:\n",
    "            client = self.client_fn(self.client_cls, self.cfg, id, self.latest_round, t, self.loss_fn)\n",
    "            len_clients_ds.append(len(client.train_ds))\n",
    "            \n",
    "            self.communicate(client) \n",
    "            client.fit()\n",
    "\n",
    "            client.communicate(self) \n",
    "            self.latest_round[id] = t \n",
    "\n",
    "        self.aggregate(lst_active_ids, t, len_clients_ds)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    self.writer.save(res)\n",
    "    self.writer.finish()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def evaluate(self: FLAgent, t):\n",
    "    lst_train_res = []\n",
    "    lst_test_res = []\n",
    "    for id in range(self.cfg.num_clients):\n",
    "        client = self.client_fn(self.client_cls, self.cfg, id, self.latest_round, t, self.loss_fn)\n",
    "        \n",
    "        res_train = client.evaluate_local(loader= 'train')\n",
    "        lst_train_res.append(res_train)\n",
    "\n",
    "        res_test = client.evaluate_local(loader= 'test')\n",
    "        lst_test_res.append(res_test)\n",
    "    return lst_train_res, lst_test_res    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will adjust the string reprsntation of the client abstraction to make it more meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def __str__(self: FLAgent) -> str:\n",
    "    return f'''{self.__class__.__name__}: {self.__class__.__name__}\n",
    "    Index : {self.id}\n",
    "    Model: {self.model.__class__.__name__}\n",
    "    Criterion: {self.criterion.__class__.__name__}\n",
    "    Optimizer: {self.optimizer.__class__.__name__}'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def clear_model(self: FLAgent):\n",
    "    self.model = None if hasattr(self, 'model') else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_batch(self: FLAgent, batch):\n",
    "    return {k: v.to(self.device) for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _forward(self: FLAgent, batch):\n",
    "    X, y = batch['x'], batch['y']\n",
    "    outputs = self.model(X)\n",
    "    loss = self.criterion(outputs, y)\n",
    "    return loss, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _closure(self: FLAgent, batch: dict) -> tuple:\n",
    "    metrics = {k: 0 for k in list(self.cfg.training_metrics)}  # Ensure metrics is always defined\n",
    "\n",
    "    try:\n",
    "        loss, logits = self._forward(batch)\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        y_pred = probs.argmax(dim=-1)\n",
    "        y_true = batch[self.label_key]\n",
    "\n",
    "        if hasattr(self, \"training_metrics\") and self.cfg.training_metrics:\n",
    "            if hasattr(self, \"tokenizer\"):\n",
    "                metrics = self.training_metrics.compute(y_pred=y_pred, y_true=y_true, tokenizer=self.tokenizer)\n",
    "            else:\n",
    "                metrics = self.training_metrics.compute(y_pred=y_pred, y_true=y_true)\n",
    "\n",
    "    except Exception as e:\n",
    "        return torch.tensor(0.0, dtype=torch.float32, device=self.device), metrics  # Return safe values\n",
    "\n",
    "    return loss, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _run_batch(self: FLAgent, batch: dict) -> tuple:\n",
    "    self.model.zero_grad()\n",
    "    loss, metrics = self._closure(batch)\n",
    "\n",
    "    if loss.item() == 0.0:\n",
    "        return loss, metrics\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    if self.cfg.model.grad_norm_clip:\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.cfg.model.grad_norm_clip)\n",
    "\n",
    "    self.optimizer.step()\n",
    "\n",
    "    return loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _run_epoch(self: FLAgent):\n",
    "\n",
    "    for i, batch in enumerate(self.train_loader):\n",
    "        batch = self.get_batch(batch)\n",
    "        self._run_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def fit(self: FLAgent) -> dict:\n",
    "    \n",
    "    self.model = self.model.to(self.device)\n",
    "    self.model.train()\n",
    "    for _ in range(self.cfg.local_epochs):\n",
    "        self._run_epoch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def evaluate_local(self: FLAgent, loader= 'train') -> dict:\n",
    "    total_loss = 0\n",
    "    lst_metrics = []\n",
    "\n",
    "    self.model = self.model.to(self.device)\n",
    "    self.model.eval()\n",
    "    num_eval = 0\n",
    "    data_loader = self.train_loader if loader == 'train' else self.test_loader\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            batch = self.get_batch(batch)\n",
    "            loss, metrics = self._closure(batch)                 \n",
    "\n",
    "            if not math.isnan(loss.item()):\n",
    "                total_loss += loss.item()  \n",
    "                num_eval += len(batch[self.data_key])  # Ensure num_eval is updated\n",
    "                lst_metrics.append(metrics)           \n",
    "    \n",
    "    avg_loss = total_loss / num_eval if num_eval > 0 else 0.0\n",
    "\n",
    "    if lst_metrics:\n",
    "        total_metrics = {k: sum(m.get(k, 0) for m in lst_metrics) / len(lst_metrics) for k in self.cfg.test_metrics}\n",
    "    else:\n",
    "        total_metrics = {k: 0.0 for k in self.cfg.test_metrics}\n",
    "\n",
    "    return {\"loss\": avg_loss, \"metrics\": total_metrics}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def save_state(self: FLAgent, state_dict):  # noqa: F811\n",
    "    # save the model to self.cfg.save_dir/comm_round/f\"local_output_{id}\"/state.pth\n",
    "    \n",
    "    state_path = os.path.join(self.cfg.save_dir, \n",
    "                              str(self.t),\n",
    "                              f\"local_output_{self.id}\",\n",
    "                              \"state.pth\")\n",
    "    if not os.path.exists(os.path.dirname(state_path)):\n",
    "        os.makedirs(os.path.dirname(state_path))\n",
    "\n",
    "    state_dict['model'] = self.model.state_dict()\n",
    "    state_dict['optimizer'] = self.optimizer.state_dict()\n",
    "\n",
    "    torch.save(state_dict, state_path)\n",
    "\n",
    "    if self.role == AgentRole.CLIENT:\n",
    "        save_space(self)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To do: implement the communication process in **Protobuf**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communication\n",
    "\n",
    "Communication refers to the process of downloading and uploading models from the server and to the client. Since we are safeguarding against memory issues, we use sequential client processing and disk checkpointing as our tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def communicate(self: Agent, another_agent: Agent):  # noqa: F811\n",
    "    if self.role == AgentRole.CLIENT:\n",
    "        self.save_state(self.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aggegation for `fedavg` is defined as:\n",
    "\n",
    "$$m_t \\leftarrow \\sum_{k \\in S_t} n_k$$\n",
    "$$W_{global}^{(t + 1)} \\leftarrow \\sum_{k \\in S_t} \\frac{n_k}{m_t} w_k^{(t + 1)}$$\n",
    "\n",
    "where $S_t$ is the set of active clients at communication round $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def aggregate(self: FLAgent, lst_active_ids, comm_round, len_clients_ds):\n",
    "        \n",
    "    m_t = sum(len_clients_ds)\n",
    "    with torch.no_grad():\n",
    "        for i, id in enumerate(lst_active_ids):\n",
    "            state_path = os.path.join(self.cfg.save_dir, \n",
    "                                    str(comm_round),\n",
    "                                    f\"local_output_{id}\",\n",
    "                                    \"state.pth\")\n",
    "            \n",
    "            state = torch.load(state_path, weights_only=False)\n",
    "            client_state_dict = state['model']\n",
    "\n",
    "            if i == 0:\n",
    "                global_model = {\n",
    "                    key: torch.zeros_like(value) \n",
    "                    for key, value in client_state_dict.items()\n",
    "                }\n",
    "\n",
    "            n_k = len_clients_ds[i]\n",
    "            weight =  n_k / m_t \n",
    "\n",
    "        \n",
    "            for key in client_state_dict.keys():\n",
    "                global_model[key].add_(weight * client_state_dict[key])\n",
    "\n",
    "\n",
    "        server_state = {\n",
    "            'model': global_model,\n",
    "        }\n",
    "\n",
    "        server_state_path = os.path.join(self.cfg.save_dir, \n",
    "                                    str(comm_round),\n",
    "                                    \"global_model\",\n",
    "                                    \"state.pth\")\n",
    "        os.makedirs(os.path.dirname(server_state_path), exist_ok=True)\n",
    "\n",
    "        torch.save(server_state, server_state_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fedu Agent (MTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This client uses **Multi-Task-Learning** scheme to personalize the models in a non-iid setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Fedu(FLAgent):\n",
    "    def __init__(self, \n",
    "                 id,\n",
    "                 cfg,\n",
    "                 state= None,\n",
    "                 role= AgentRole.CLIENT,\n",
    "                 block= None):\n",
    "        \n",
    "        super().__init__(id, cfg, state, role, block)\n",
    "\n",
    "        b = np.random.uniform(0,1,size=(self.cfg.num_clients, self.cfg.num_clients))\n",
    "        b_symm = (b + b.T)/2\n",
    "        b_symm[b_symm < 0.25] = 0\n",
    "        self.alk_connection = b_symm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Algorithm learns a model per client, and add a new aggregation scheme defined as\n",
    "\n",
    "$$ W_{k}^{(t)} = W_{k, R}^{(t)} - \\lambda \\eta_2 \\sum_{\\ell \\in N_k} a_{k, \\ell} (W_{k, R}^{(t)} - W_{\\ell, R}^{(t)})$$\n",
    "\n",
    "where $\\lambda$ is a regularization parameter and $\\eta_2$ is defined as $$\\eta_2 = \\eta_1 * R $$\n",
    "\n",
    "such that $\\eta_1$ is the local learning rate, and $R$ is the number of lcoal iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def aggregate(self: Fedu, lst_active_ids, comm_round, len_clients_ds):\n",
    "\n",
    "    global_lr = float(self.cfg.lr) * float(self.cfg.local_epochs)\n",
    "    reg_param = self.cfg.lambda_\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, id in enumerate(lst_active_ids):\n",
    "            state_path = os.path.join(self.cfg.save_dir, \n",
    "                                    str(comm_round),\n",
    "                                    f\"local_output_{id}\",\n",
    "                                    \"state.pth\")\n",
    "            \n",
    "            state = torch.load(state_path, weights_only= False)\n",
    "            client_state_dict = state['model']\n",
    "\n",
    "            client_diff = {\n",
    "                key: torch.zeros_like(value) \n",
    "                for key, value in client_state_dict.items()\n",
    "            }\n",
    "            \n",
    "            for j, other_id in enumerate(lst_active_ids):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                other_state_path = os.path.join(self.cfg.save_dir,\n",
    "                                                str(comm_round),\n",
    "                                                f\"local_output_{other_id}\",\n",
    "                                                \"state.pth\")\n",
    "                \n",
    "                other_state = torch.load(other_state_path, weights_only= False)\n",
    "                other_state_dict = other_state['model']\n",
    "\n",
    "                weight = self.alk_connection[int(id)][int(other_id)]\n",
    "                for key in client_state_dict.keys():\n",
    "                    client_diff[key].add_(weight * (client_state_dict[key] - other_state_dict[key]))\n",
    "\n",
    "            for key in client_state_dict:\n",
    "                client_state_dict[key].sub_(global_lr * reg_param * client_diff[key])\n",
    "\n",
    "            clinet_state = {\n",
    "                'model': client_state_dict,\n",
    "            }\n",
    "\n",
    "            agg_client_state_path = os.path.join(self.cfg.save_dir,\n",
    "                                                 str(comm_round),\n",
    "                                                 f\"aggregated_model_{id}\",\n",
    "                                                 \"state.pth\")\n",
    "            \n",
    "            if not os.path.exists(os.path.dirname(agg_client_state_path)):\n",
    "                os.makedirs(os.path.dirname(agg_client_state_path))\n",
    "\n",
    "            torch.save(clinet_state, agg_client_state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMTL-G (MTL)\n",
    "Distributed Multi-Task Learning over Graphs: A game-theoretic approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DMTL(FLAgent):\n",
    "    def __init__(self, \n",
    "                 id,\n",
    "                 cfg,\n",
    "                 state= None,\n",
    "                 role= AgentRole.CLIENT,\n",
    "                 block= None):\n",
    "        \n",
    "        super().__init__(id, cfg, state, role, block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def runFL(self: DMTL):\n",
    "    res =  []\n",
    "    all_ids = self.client_selector.select()\n",
    "    \n",
    "    for t in range(1, self.cfg.n_rounds + 1):\n",
    "        lst_active_ids = all_ids[t]\n",
    "        len_clients_ds = {}\n",
    "               \n",
    "        for id in lst_active_ids:\n",
    "            client = self.client_fn(self.client_cls, self.cfg, id, self.latest_round, t, self.loss_fn, to_read_from= 'local_output_aligned_')\n",
    "            len_clients_ds[id] = len(client.train_ds)\n",
    "            \n",
    "            self.communicate(client) \n",
    "            client.fit()\n",
    "\n",
    "            client.communicate(self) \n",
    "            self.latest_round[id] = t \n",
    "\n",
    "        self.aggregate(lst_active_ids, t, len_clients_ds)\n",
    "        self.extra_computation(lst_active_ids, t)\n",
    "        \n",
    "        train_res, test_res = self.evaluate(t)\n",
    "        train_df, test_df = self.writer.write(lst_active_ids, train_res, test_res, t) \n",
    "        res.append((train_df, test_df))\n",
    "        \n",
    "    self.writer.save(res)\n",
    "    self.writer.finish()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def evaluate(self: DMTL, t):\n",
    "    lst_train_res = []\n",
    "    lst_test_res = []\n",
    "    for id in range(self.cfg.num_clients):\n",
    "        client = self.client_fn(self.client_cls, self.cfg, id, self.latest_round, t, self.loss_fn, to_read_from= 'local_output_aligned_')\n",
    "        \n",
    "        res_train = client.evaluate_local(loader= 'train')\n",
    "        lst_train_res.append(res_train)\n",
    "\n",
    "        res_test = client.evaluate_local(loader= 'test')\n",
    "        lst_test_res.append(res_test)\n",
    "    return lst_train_res, lst_test_res    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The communication in DMTL is a matter of sending (saving to the disk) two things, the classification head and a randomly picked data represntation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def save_state(self: DMTL, state_dict):  # noqa: F811\n",
    "    # save the model to self.cfg.save_dir/comm_round/f\"local_output_{id}\"/state.pth\n",
    "    \n",
    "    state_path = os.path.join(self.cfg.save_dir, str(self.t), f\"local_output_{self.id}\", \"state.pth\")\n",
    "    if not os.path.exists(os.path.dirname(state_path)):\n",
    "        os.makedirs(os.path.dirname(state_path))\n",
    "\n",
    "    state_dict['model'] = self.model.state_dict()\n",
    "    state_dict['optimizer'] = self.optimizer.state_dict()\n",
    "\n",
    "    # pick a random data point from the train_ds and save it to the state_dict\n",
    "    data_point = self.train_ds[np.random.randint(0, len(self.train_ds))]\n",
    "    data_point = self.get_batch(data_point)\n",
    "    data = data_point['x']\n",
    "    batched_data_point = data.view(1, 3, 32, 32)\n",
    "    state_dict['h'] = self.model.encoder(batched_data_point)\n",
    "\n",
    "    torch.save(state_dict, state_path)\n",
    "\n",
    "    if self.role == AgentRole.CLIENT:\n",
    "        save_space(self)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a weighted graph where the weights are defined as:\n",
    "\n",
    "$\\begin{align}\n",
    "\\operatorname{Sim} = \\sum_{i \\in S} \\alpha \\cdot \\operatorname{Sim}_{\\text {head }}(C_j)+(1-\\alpha) \\cdot \\operatorname{Sim}_{\\mathrm{repr}}(C_j)\n",
    "\\end{align}$\n",
    "\n",
    "\n",
    "$\\begin{align}\n",
    "\\operatorname{Sim}_{\\text {head }}(C_j)=\\frac{1}{|C_j|^2} \\sum_{k, \\ell \\in C_j} \\left\\|\\bm{w}_k-\\bm{w}_\\ell\\right\\|, \\nonumber \\\\ \\operatorname{Sim}_{\\text {repr }}(C_j)=\\frac{1}{|C_j|^2} \\sum_{k, \\ell \\in C_j} \\cos \\left(\\bm{h}_k^{\\text { }}, \\bm{h}_\\ell^{\\text { }}\\right)\n",
    "\\end{align}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def model_similarity(self: DMTL, model1, model2):\n",
    "    total_l1_norm = 0.0\n",
    "    \n",
    "    for key in model1.keys():\n",
    "        param1 = model1[key]\n",
    "        param2 = model2[key]\n",
    "        \n",
    "        total_l1_norm += torch.norm(param1 - param2, p=1).item()\n",
    "    \n",
    "    return total_l1_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def h_similarity(self: DMTL, h1, h2):\n",
    "    h1, h2 = h1.squeeze(0), h2.squeeze(0)\n",
    "    return torch.nn.functional.cosine_similarity(h1, h2, dim=0).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def build_graph(self: DMTL, lst_active_ids, comm_round):\n",
    "\n",
    "    num_active = len(lst_active_ids)\n",
    "    graph = np.random.rand(num_active, num_active)\n",
    "    graph = graph / graph.sum(axis=1)[:, None]\n",
    "\n",
    "    visited = {}\n",
    "    for i, id in enumerate(lst_active_ids):\n",
    "        state_path = os.path.join(self.cfg.save_dir, str(comm_round), f\"local_output_{id}\", \"state.pth\")\n",
    "        state = torch.load(state_path, weights_only= False)\n",
    "        model1 = state['model']\n",
    "        h1 = state['h']\n",
    "\n",
    "        for j, other_id in enumerate(lst_active_ids):\n",
    "            if i == j or (id, other_id) in visited:\n",
    "                continue\n",
    "            other_state_path = os.path.join(self.cfg.save_dir, str(comm_round), f\"local_output_{other_id}\", \"state.pth\")\n",
    "            other_state = torch.load(other_state_path, weights_only= False)\n",
    "            model2 = other_state['model']\n",
    "            h2 = other_state['h']\n",
    "\n",
    "            w_sim = self.model_similarity(model1, model2)\n",
    "            h_sim = self.h_similarity(h1, h2)\n",
    "\n",
    "            graph[i][j] = (self.cfg.alpha) * w_sim + (1-self.cfg.alpha) * h_sim\n",
    "            graph[i][j] = graph[i][j]\n",
    "\n",
    "            visited[(id, other_id)] = True\n",
    "            visited[(other_id, id)] = True\n",
    "\n",
    "    edges = []\n",
    "    for i in range(num_active):\n",
    "        for j in range(num_active):\n",
    "            if i != j:\n",
    "                edges.append((i, j, graph[i][j]))\n",
    "                \n",
    "    G = nx.Graph()\n",
    "    G.add_weighted_edges_from(edges)\n",
    "\n",
    "    for node, label in zip(list(range(num_active)), lst_active_ids):\n",
    "        G.nodes[node]['label'] = label\n",
    "        \n",
    "    return G, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a wighted graph, we nedd to form the coalitions (detecting the communities). We do so by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_coalitions(self: DMTL, G):\n",
    "    correct_clients_indices = nx.get_node_attributes(G, 'label')\n",
    "    partitions = community_louvain.best_partition(G)\n",
    "    communities = defaultdict(list)\n",
    "    for client, community in partitions.items():\n",
    "        communities[community].append(client)\n",
    "    communities = dict(communities)\n",
    "\n",
    "    for community, clients in communities.items():\n",
    "        communities[community] = [correct_clients_indices[client] for client in clients]\n",
    "\n",
    "    return communities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [19, 16, 15, 5, 4], 1: [12, 14, 7, 3, 6]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "node_labels = {0: 19, 1: 16, 2: 15, 3: 5, 4: 4, 5: 12, 6: 14, 7: 7, 8: 3, 9: 6}\n",
    "communities = {0:[0, 1, 2, 3, 4], 1:[5, 6, 7, 8, 9]}\n",
    "\n",
    "for community, clients in communities.items():\n",
    "        communities[community] = [node_labels[client] for client in clients]\n",
    "communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aggregation rule here is two-folds:\n",
    "- Representations are aggregated as:\n",
    "  $$ h_c = \\sum_{k \\in C_{j}} \\frac{\\zeta_k}{\\sum_{k \\in C_{j}} \\zeta_k}h_k$$\n",
    "\n",
    "  where $\\zeta$ is the shapely value.\n",
    "\n",
    "- Classification heads are aggregated as:\n",
    "$$  w_k^{(t+1)} = w_{k, R}^{(t)} - \\lambda \\eta_2 \\sum_{\\ell \\in C_{j}} a_{k, \\ell} (w_{k,R}^{(t)} - w_{\\ell, R}^{(t)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_shapley_vals(self: DMTL):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the server, we are doing the followin steps:\n",
    "- Form the coalitions.\n",
    "  - First, for the weighted undirected graph $\\mathcal{g}$.\n",
    "  - Second, pass this graph to the louvian algorithm to get the communities.\n",
    "- aggregate based on the equations above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Example data with integer labels for nodes and weights\n",
    "# edges = [\n",
    "#     (0, 1, 0.5),  # Edge between node 0 and 1 with weight 0.5\n",
    "#     (0, 2, 0.8),  # Edge between node 0 and 2 with weight 0.8\n",
    "#     (1, 2, 0.7),  # Edge between node 1 and 2 with weight 0.7\n",
    "# ]\n",
    "\n",
    "# # Create the graph\n",
    "# G = nx.Graph()\n",
    "# G.add_weighted_edges_from(edges)\n",
    "\n",
    "# # Visualize the graph\n",
    "# pos = nx.spring_layout(G)  # Positions for all nodes using spring layout\n",
    "\n",
    "# # Draw the graph\n",
    "# plt.figure(figsize=(8, 6))\n",
    "\n",
    "# # Draw nodes\n",
    "# nx.draw_networkx_nodes(G, pos, node_size=700, node_color='skyblue', alpha=0.7)\n",
    "\n",
    "# # Draw edges with weights as labels\n",
    "# nx.draw_networkx_edges(G, pos, width=2, alpha=0.7, edge_color='gray')\n",
    "\n",
    "# # Draw node labels\n",
    "# nx.draw_networkx_labels(G, pos, font_size=16, font_weight='bold', font_color='black')\n",
    "\n",
    "# # Draw edge labels (weights)\n",
    "# edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "# nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=12)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.title(\"NetworkX Graph with Node Labels and Edge Weights\")\n",
    "# plt.axis('off')  # Turn off the axis for better visualization\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def aggregate(self: DMTL, lst_active_ids, comm_round, len_clients_ds):\n",
    "\n",
    "    self.graph, self.akl_connection = self.build_graph(lst_active_ids, comm_round)\n",
    "    graph_path = os.path.join(self.cfg.save_dir, str(comm_round), f\"graph_{str(comm_round)}.gpickle\")\n",
    "    with open(graph_path, \"wb\") as f:\n",
    "        pickle.dump(self.graph, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    self.coalitions = self.get_coalitions(self.graph)\n",
    "    coalitions_path = os.path.join(self.cfg.save_dir, str(comm_round), \"coalitions.pth\")\n",
    "    torch.save(self.coalitions, coalitions_path)\n",
    "\n",
    "    global_lr = float(self.cfg.lr) * float(self.cfg.local_epochs)\n",
    "    reg_param = self.cfg.lambda_\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        coalitions_reprs = {}\n",
    "        for col_ind, lst_clients in self.coalitions.items():\n",
    "\n",
    "            m_t = sum(len_clients_ds[id] for id in lst_clients)\n",
    "            for i, id in enumerate(lst_clients):\n",
    "                if not id in lst_active_ids:\n",
    "                    continue\n",
    "                state_path = os.path.join(self.cfg.save_dir, str(comm_round), f\"local_output_{id}\", \"state.pth\")\n",
    "                state = torch.load(state_path, weights_only= False)\n",
    "                client_h = state['h']\n",
    "\n",
    "                if i == 0:\n",
    "                    col_repr = torch.zeros_like(client_h)\n",
    "\n",
    "                n_k = len_clients_ds[id]\n",
    "                weight =  n_k / m_t \n",
    "\n",
    "                col_repr.add_(weight * client_h)\n",
    "            coalitions_reprs[col_ind] = col_repr\n",
    "            \n",
    "\n",
    "        for col_ind, lst_clients in self.coalitions.items():\n",
    "            for i, id in enumerate(lst_clients):\n",
    "                if not id in lst_active_ids:\n",
    "                    continue\n",
    "                state_path = os.path.join(self.cfg.save_dir, str(comm_round), f\"local_output_{id}\", \"state.pth\")\n",
    "                \n",
    "                state = torch.load(state_path, weights_only= False)\n",
    "                client_model = state['model']\n",
    "\n",
    "                client_diff = {\n",
    "                    key: torch.zeros_like(value) \n",
    "                    for key, value in client_model.items() if key.startswith(\"fc2\") or key.startswith(\"dropout\")\n",
    "                }\n",
    "\n",
    "                for j, other_id in enumerate(lst_clients):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    other_state_path = os.path.join(self.cfg.save_dir, str(comm_round), f\"local_output_{other_id}\", \"state.pth\")\n",
    "                    \n",
    "                    other_state = torch.load(other_state_path, weights_only= False)\n",
    "                    other_client_model = other_state['model']\n",
    "\n",
    "                    a_kl = self.akl_connection[i, j]\n",
    "                    for key in client_model.keys():\n",
    "                        if key.startswith(\"fc2\") or key.startswith(\"dropout\"):\n",
    "                            client_diff[key].add_(a_kl * (client_model[key] - other_client_model[key]))\n",
    "\n",
    "                for key in client_model.keys():\n",
    "                    if key.startswith(\"fc2\") or key.startswith(\"dropout\"):\n",
    "                        client_model[key].sub_(global_lr * reg_param * client_diff[key])\n",
    "\n",
    "                clinet_state = {\n",
    "                    'model': client_model,\n",
    "                    'h': state['h'],\n",
    "                    'h_c': coalitions_reprs[col_ind],\n",
    "                }\n",
    "\n",
    "                agg_client_state_path = os.path.join(self.cfg.save_dir, str(comm_round), f\"aggregated_model_{id}\", \"state.pth\")\n",
    "                \n",
    "                if not os.path.exists(os.path.dirname(agg_client_state_path)):\n",
    "                    os.makedirs(os.path.dirname(agg_client_state_path))\n",
    "\n",
    "                torch.save(clinet_state, agg_client_state_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to align the represntation of the coalition with the local represntation. This process is done as follows:\n",
    "\n",
    "$$\\min_{\\phi_i} \\left\\|\\bm{\\phi}_i(x)- \\bm{h}_c\\right\\|^2 ; \\hspace{0.3cm} \\forall x \\in D_k$$\n",
    "\n",
    "We prevent the coallpse of reprenstations as follows:\n",
    "\n",
    "$$\\bm{h}_c^{(i+1)} = \\beta \\bm{h}_c^{(i)} + (1-\\beta) \\bm{\\phi}_i(x^{(i)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def extra_computation(self: DMTL, lst_active_ids, comm_round):\n",
    "    \n",
    "    for id in lst_active_ids:\n",
    "        client = self.client_fn(self.client_cls, self.cfg, id, self.latest_round, comm_round, self.loss_fn, to_read_from= 'aggregated_model_', extra= True)\n",
    "        \n",
    "        client.model.train()\n",
    "        for param in client.model.classifier.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        client.model = client.model.to(client.device)\n",
    "        client.h_c = client.h_c.to(client.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(client.model.encoder.parameters(), lr=0.001)\n",
    "        for i, batch in enumerate(client.train_loader):\n",
    "            batch = client.get_batch(batch)\n",
    "            X = batch['x']\n",
    "            optimizer.zero_grad()\n",
    "            h_prime = client.model.encoder(X)\n",
    "            \n",
    "            loss = client.alignment_criterion()(h_prime, client.h_c)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                client.h_c.data.mul_(self.cfg.beta1).add_(1-self.cfg.beta1, h_prime.data)\n",
    "\n",
    "        \n",
    "        state = {\n",
    "            'model': client.model,\n",
    "            'h_c': client.h_c,\n",
    "            'h': client.h\n",
    "        }\n",
    "\n",
    "        state_path = os.path.join(self.cfg.save_dir, str(comm_round), f\"local_output_aligned_{id}\", \"state.pth\")\n",
    "        \n",
    "        torch.save(state, state_path)\n",
    "\n",
    "        for param in client.model.classifier.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEFT Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PeftAgent(FLAgent):\n",
    "    def __init__(self,\n",
    "                 cfg,\n",
    "                 block,\n",
    "                 id,\n",
    "                 state= None,\n",
    "                 role= \"client\",\n",
    "                 **adapter_settings):\n",
    "        super().__init__(cfg, block, id, state, role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def peftify(self: PeftAgent):\n",
    "    # extract only the adapter's parameters from the model and store them in a dictionary\n",
    "    self.params_dict_old = deepcopy(\n",
    "        OrderedDict((name, param.detach()) for name, param in self.model.named_parameters() if\n",
    "                    \"default\" in name))\n",
    "    \n",
    "    self.params_dict_new = deepcopy(self.params_dict_old)\n",
    "    \n",
    "    self.model.state_dict = (\n",
    "        lambda instance, *_, **__: get_peft_model_state_dict(  # noqa: F405\n",
    "            instance, self.params_dict_new, \"default\"\n",
    "        )\n",
    "    ).__get__(self.model, type(self.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch \n",
    "def init_agent(self: PeftAgent):  # noqa: F811\n",
    "    self.peftify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def save_state_(self: PeftAgent, epoch, local_dataset_len_dict, previously_selected_clients_set):  # noqa: F811\n",
    "    # save the new adapter weights to disk\n",
    "    self.save_state(epoch)\n",
    "\n",
    "    local_dataset_len_dict[self.id] = len(self.block)\n",
    "    older_adapter_weight = get_peft_model_state_dict(self.model, self.params_dict_old, \"default\")  # noqa: F405\n",
    "    set_peft_model_state_dict(self.model, older_adapter_weight, \"default\")  # noqa: F405\n",
    "    previously_selected_clients_set = previously_selected_clients_set | set({self.id})\n",
    "    last_client_id = self.id\n",
    "\n",
    "    return self.model, local_dataset_len_dict, previously_selected_clients_set, last_client_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fed-Sophia Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FedSophiaAgent(FLAgent):\n",
    "    def __init__(self,\n",
    "                 id, # the id of the agent\n",
    "                 cfg, # the configuration of the agent.\n",
    "                 state= None, # the state of the agent (model, optimizer, loss_fn), etc.\n",
    "                 role= AgentRole.CLIENT, # the role of the agent (client or server)\n",
    "                 block= None):\n",
    "        super().__init__(id, cfg, state, role, block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def train(self: FedSophiaAgent):\n",
    "    trainer = self.trainer(self) \n",
    "    client_history = trainer.fit() \n",
    "    return client_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PADG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PadgAgent(FLAgent):\n",
    "    def __init__(self,\n",
    "                 id, # the id of the agent\n",
    "                 cfg, # the configuration of the agent.\n",
    "                 state= None, # the state of the agent (model, optimizer, loss_fn), etc.\n",
    "                 role= AgentRole.CLIENT, # the role of the agent (client or server)\n",
    "                 block= None):\n",
    "        super().__init__(id, cfg, state, role, block)\n",
    "\n",
    "        if role == AgentRole.SERVER:\n",
    "            self.connections = torch.from_numpy(generate_graph(self.cfg.num_clients))  # noqa: F405\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def apply_constraints(self: PadgAgent, \n",
    "                      graph, # (np.ndarray): The input matrix.\n",
    "                      symmetrize=True, # (bool): If True, makes the matrix symmetric.\n",
    "                      normalize=True, # (bool): If True, normalizes the matrix symmetrically.\n",
    "                      threshold= 0, # (float or None): If provided, sets values below this threshold to 0.\n",
    "                      diag_fill= 0): # (float or None): If provided, fills the diagonal with this value.\n",
    "    \n",
    "\n",
    "    # Symmetrize the matrix\n",
    "    if symmetrize:\n",
    "        graph = (graph + graph.T) / 2\n",
    "\n",
    "    # Apply threshold to ensure non-negativity\n",
    "    if threshold is not None:\n",
    "        graph = torch.where(graph > threshold, graph, 0)\n",
    "\n",
    "    # Normalize the matrix symmetrically\n",
    "    if normalize:\n",
    "        row_sums = graph.sum(axis=1, keepdims=True)\n",
    "        col_sums = graph.sum(axis=0, keepdims=True)\n",
    "        norm_factor = torch.sqrt(row_sums @ col_sums)  # Symmetric normalization factor\n",
    "        graph = torch.divide(graph, norm_factor, where=norm_factor != 0)\n",
    "\n",
    "    # Fill the diagonal\n",
    "    if diag_fill is not None:\n",
    "        torch.fill_diagonal(graph, diag_fill)\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedai.models import *  # noqa: F403\n",
    "model = MLP(dim_in= 784, dim_hidden= 64, dim_out= 10)  # noqa: F405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "rand_in = torch.rand(1, 1, 28, 28)\n",
    "rand_in2 = torch.rand(1, 1, 28, 28)\n",
    "out1 = model(rand_in)\n",
    "out2 = model(rand_in2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.3843, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the KL divergence between the two outputs\n",
    "dist1 = F.softmax(out1, dim= -1)\n",
    "dist2 = F.softmax(out2, dim= -1)\n",
    "F.kl_div(dist1, dist2, reduction= 'batchmean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def compute_probs(self: PadgAgent,\n",
    "                  batch_size=32, # batch_size (int): Batch size for evaluation.\n",
    "                  return_log_probs=True): # return_log_probs (bool): If True, return log-probabilities; otherwise, return probabilities.\n",
    "    \n",
    "    # Computes probabilities or log-probabilities across the entire dataset for a given model.\n",
    "    # Ensure model is in evaluation mode\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    self.model.to(device)\n",
    "    self.model.eval()\n",
    "    \n",
    "    # Create DataLoader for the dataset\n",
    "    dataloader = DataLoader(self.train_ds, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    all_probs = []  # To store probabilities or log-probabilities for all batches\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in dataloader:  # Assuming dataset returns (inputs, labels)\n",
    "            inputs = batch['x'].to(device)  # Move to model's device\n",
    "            \n",
    "            logits = self.model(inputs)\n",
    "            \n",
    "            if return_log_probs:\n",
    "                # Convert logits to log-probabilities\n",
    "                batch_log_probs = F.log_softmax(logits, dim=-1)\n",
    "                all_probs.append(batch_log_probs)\n",
    "            else:\n",
    "                # Convert logits to probabilities\n",
    "                batch_probs = F.softmax(logits, dim=-1)\n",
    "                all_probs.append(batch_probs)\n",
    "    \n",
    "    self.model.to('cpu')\n",
    "    # Concatenate all batch probabilities/log-probabilities\n",
    "    return torch.cat(all_probs, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad(self: PadgAgent,\n",
    "                 ):\n",
    "    # compute the graident f R(w, A) w.r.t w\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def aggregate(self: PadgAgent, lst_active_ids, comm_round, len_clients_ds, one_model= False):\n",
    "    \n",
    "    visited = []\n",
    "    for i, id in enumerate(lst_active_ids):\n",
    "\n",
    "        neighbour_ids = torch.where(self.connections[id] != float(0))[0]\n",
    "\n",
    "        model_path = os.path.join(self.cfg.save_dir, \n",
    "                                   str(comm_round),\n",
    "                                   f\"local_output_{id}\",\n",
    "                                   \"pytorch_model.pth\")\n",
    "        client_state_dict = torch.load(model_path, map_location='cpu', weights_only= False)\n",
    "        self.model.load_state_dict(client_state_dict)\n",
    "        \n",
    "        neighbours_sum = {\n",
    "            key: torch.zeros_like(value) \n",
    "            for key, value in client_state_dict.items()\n",
    "        }\n",
    "            \n",
    "        probs_1 = self.compute_probs(batch_size=32, return_log_probs=True)\n",
    "        \n",
    "        for other_id in neighbour_ids:\n",
    "\n",
    "            if (other_id, id) in visited:\n",
    "                continue\n",
    "            other_model_path = os.path.join(self.cfg.save_dir, \n",
    "                                    str(comm_round),\n",
    "                                    f\"local_output_{other_id}\",\n",
    "                                    \"pytorch_model.pth\")\n",
    "            \n",
    "            other_client_state_dict = torch.load(other_model_path, map_location='cpu', weights_only= False)\n",
    "            self.model.load_state_dict(other_client_state_dict)\n",
    "            \n",
    "            probs_2 = self.compute_probs(batch_size=32, return_log_probs=False)\n",
    "\n",
    "            kl_div = F.kl_div(probs_1, probs_2, reduction= 'batchmean').to('cpu')\n",
    "            self.connections[id][other_id] -= self.cfg.server_lr * self.cfg.lambda_ * kl_div\n",
    "\n",
    "            # apply constraints to the KL divergence\n",
    "            self.connections[id][other_id] = self.apply_constraints(self.connections[id][other_id])\n",
    "            self.connections[id][other_id] = self.connections[other_id][id]\n",
    "\n",
    "            visited.append((id, other_id))\n",
    "            visited.append((other_id, id))\n",
    "            \n",
    "        for other_id in neighbour_ids:\n",
    "            other_model_path = os.path.join(self.cfg.save_dir, \n",
    "                                    str(comm_round),\n",
    "                                    f\"local_output_{other_id}\",\n",
    "                                    \"pytorch_model.pth\")\n",
    "            other_client_state_dict = torch.load(other_model_path, map_location='cpu', weights_only= False)\n",
    "\n",
    "            weight = self.connections[id][other_id]\n",
    "            for key in other_client_state_dict.keys():\n",
    "                neighbours_sum[key].data += weight * other_client_state_dict[key].data\n",
    "\n",
    "        # for key in neighbours_sum.keys():\n",
    "            # neighbours_sum[key].data /= len(neighbour_ids)\n",
    "\n",
    "        for key in client_state_dict.keys():\n",
    "            client_state_dict[key].data = self.cfg.beta * client_state_dict[key].data + (1 - self.cfg.beta) * neighbours_sum[key].data\n",
    "\n",
    "    \n",
    "        # save the updated model to the disk\n",
    "        self.save_state(client_state_dict, comm_round + 1, id)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIRA Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mira clients have more parameters. Since it's a client for LLM in principle, we need to feed the generation dataset (the dataset of text ids at the end layer not the logits). Also, a tokenizer and a collate function that will be used for the generation and the data loader construction processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AgentMira(FLAgent):\n",
    "    def __init__(self,\n",
    "                 data_dict: dict,\n",
    "                 model: torch.nn.Module,\n",
    "                 criterion,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 id: int,\n",
    "                 gen_data_dict: dict,\n",
    "                 tokenizer: AutoTokenizer,\n",
    "                 collat_fn: LLMDataCollator,\n",
    "                 cfg: DictConfig) -> None:\n",
    "            \n",
    "        super().__init__(data_dict, model, criterion, optimizer, id)\n",
    "        \n",
    "        self.train_ds_genr = gen_data_dict['train']\n",
    "        self.test_ds_genr = gen_data_dict['test']\n",
    "        self.tokenizer = tokenizer\n",
    "        self.collat_fn = collat_fn\n",
    "        self.cfg = cfg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for us to save space, we will replace the original model with only the trainable peft model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Mira Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the following:\n",
    "- Define a Mira client.\n",
    "- inspect the `init_local_train` and `terminate_local_train` methods and their effect on the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# from transformers import AutoModelForCausalLM\n",
    "# gpt2 = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "# base_model = deepcopy(gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/miniconda3/envs/fedai/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1150: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# #| hide\n",
    "# config = LoraConfig(\n",
    "#     r=8,# arbitrary numbr but usually 8, 16, 32, 64, 128\n",
    "#     target_modules=['c_attn'],\n",
    "#     lora_alpha=8,\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "#     )\n",
    "\n",
    "# peft_model = get_peft_model(gpt2, config)\n",
    "# mira  = AgentMira(DataDict, peft_model, criterion, optimizer, 0, train_dataset, test_dataset, None, None, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us inpect the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
