{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Fill in a module description here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp vision.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *  # noqa: F403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.utils import *  # noqa: F403\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from peft import *  # noqa: F403"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MNISTCNNEncoder(nn.Module):\n",
    "#     def __init__(self, in_channels=1, args=None):\n",
    "#         super(MNISTCNNEncoder, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels, 10, kernel_size=5)\n",
    "#         self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "#         self.conv2_drop = nn.Dropout2d()\n",
    "#         self.fc1 = nn.Linear(320, 50)\n",
    "#         # self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "#         x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "#         x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         return x\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MNISTCNNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=1, img_size=28, hidden_dim=512):\n",
    "        super(MNISTCNNEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        final_size = img_size // 2 // 2\n",
    "        self.fc1 = nn.Linear(64 * final_size * final_size, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndim == 4 and x.shape[1] not in (1, 3) and x.shape[-1] in (1, 3):\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.size(0), -1)# x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Classification Head Model\n",
    "class MNISTCNNClassificationHead(nn.Module):\n",
    "    def __init__(self, hidden_dim= 512, num_classes=10):\n",
    "        super(MNISTCNNClassificationHead, self).__init__()\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "class MNISTCNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, img_size= 28, hidden_dim=512, num_classes=10):\n",
    "        super(MNISTCNN, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.encoder = MNISTCNNEncoder(in_channels=in_channels, img_size= img_size, hidden_dim=hidden_dim)\n",
    "        self.classifier = MNISTCNNClassificationHead(hidden_dim= hidden_dim, num_classes= num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndim == 4 and x.shape[1] not in (1, 3) and x.shape[-1] in (1, 3):\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "inp = torch.randn(1, 3, 32, 32)  # Example input\n",
    "enc = MNISTCNNEncoder(in_channels=3, img_size=32, hidden_dim=512)\n",
    "\n",
    "print(enc(inp).shape)\n",
    "model = MNISTCNN(in_channels=3, img_size=32, hidden_dim=512, num_classes=10)\n",
    "out = model(inp)\n",
    "print(out.shape)  # Should print torch.Size([1, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)  \n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Encoder Model\n",
    "class CIFAR10Encoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, img_size= 32, hidden_dim=512):\n",
    "        super(CIFAR10Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Compute the flattened size dynamically at initialization\n",
    "        final_size = img_size // 2 // 2 // 2  # 3 pool layers divide the size by 2 three times\n",
    "        self.fc1 = nn.Linear(128 * final_size * final_size, hidden_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "# Classification Head Model\n",
    "class CIFAR10ClassificationHead(nn.Module):\n",
    "    def __init__(self, hidden_dim= 512, num_classes=10):\n",
    "        super(CIFAR10ClassificationHead, self).__init__()\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self, in_channels=3, img_size= 32, hidden_dim=512, num_classes=10):\n",
    "        super(CIFAR10Model, self).__init__()\n",
    "        self.encoder = CIFAR10Encoder(in_channels=in_channels, img_size= img_size, hidden_dim=hidden_dim)\n",
    "        self.classifier = CIFAR10ClassificationHead(hidden_dim= hidden_dim, num_classes= num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "model = CIFAR10Model(in_channels=3, img_size= 32,hidden_dim=1024, num_classes=100)\n",
    "inp = torch.randn(1, 3, 32, 32)\n",
    "out = model(inp)\n",
    "print(out.shape)  # Should output torch.Size([1, 512])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtune.models.llama2 import llama2_7b, lora_llama2_7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# base_model = llama2_7b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lora_model = lora_llama2_7b(lora_attn_modules=[\"q_proj\", \"v_proj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'instruction': 'When did Virgin Australia start operating?', 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\", 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.', 'category': 'closed_qa'}, {'instruction': 'Which is a species of fish? Tope or Rope', 'context': '', 'response': 'Tope', 'category': 'classification'}, {'instruction': 'Why can camels survive for long without water?', 'context': '', 'response': 'Camels use the fat in their humps to keep them filled with energy and hydration for long periods of time.', 'category': 'open_qa'}, {'instruction': \"Alice's parents have three daughters: Amy, Jessy, and whatâ€™s the name of the third daughter?\", 'context': '', 'response': 'The name of the third daughter is Alice', 'category': 'open_qa'}, {'instruction': 'When was Tomoaki Komorida born?', 'context': 'Komorida was born in Kumamoto Prefecture on July 10, 1981. After graduating from high school, he joined the J1 League club Avispa Fukuoka in 2000. Although he debuted as a midfielder in 2001, he did not play much and the club was relegated to the J2 League at the end of the 2001 season. In 2002, he moved to the J2 club Oita Trinita. He became a regular player as a defensive midfielder and the club won the championship in 2002 and was promoted in 2003. He played many matches until 2005. In September 2005, he moved to the J2 club Montedio Yamagata. In 2006, he moved to the J2 club Vissel Kobe. Although he became a regular player as a defensive midfielder, his gradually was played less during the summer. In 2007, he moved to the Japan Football League club Rosso Kumamoto (later Roasso Kumamoto) based in his local region. He played as a regular player and the club was promoted to J2 in 2008. Although he did not play as much, he still played in many matches. In 2010, he moved to Indonesia and joined Persela Lamongan. In July 2010, he returned to Japan and joined the J2 club Giravanz Kitakyushu. He played often as a defensive midfielder and center back until 2012 when he retired.', 'response': 'Tomoaki Komorida was born on July 10,1981.', 'category': 'closed_qa'}]\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import urllib.request\n",
    "# import json \n",
    "# # download th e dataset from link\n",
    "# file_path = \"https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl\"\n",
    "\n",
    "# # get the file name from the url\n",
    "# file_name = os.path.basename(file_path)\n",
    "# # download the file\n",
    "# urllib.request.urlretrieve(file_path, file_name)\n",
    "# # read the file\n",
    "# with open(file_name, 'r') as f:\n",
    "#     data = [json.loads(line) for line in f]\n",
    "# # print the first 5 lines\n",
    "# print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
