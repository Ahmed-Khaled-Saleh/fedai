{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Fill in a module description here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp FLdataBlcok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *  # noqa: F403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class LLMDataCollator(object):\n",
    "#     \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "#     tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "#     def __call__(self, instances):\n",
    "#         input_ids, labels, task = tuple([instance[key] for instance in instances]\n",
    "#                                   for key in (\"input_ids\", \"labels\", \"task\"))\n",
    "#         input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "#             input_ids,\n",
    "#             batch_first=True,\n",
    "#             padding_value=self.tokenizer.pad_token_id)\n",
    "#         labels = torch.nn.utils.rnn.pad_sequence(\n",
    "#             labels,\n",
    "#             batch_first=True,\n",
    "#             padding_value=IGNORE_INDEX)\n",
    "#         return dict(\n",
    "#             input_ids=input_ids,\n",
    "#             labels=labels,\n",
    "#             attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "#             task=task\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LLMDataset(Dataset):\n",
    "#     def __init__(self,\n",
    "#                  data,\n",
    "#                  tokenizer,\n",
    "#                  use_prompts,\n",
    "#                  generation=False):\n",
    "#         super(LLMDataset, self).__init__()\n",
    "        \n",
    "#         if use_prompts:\n",
    "#             # prompt template from alpaca\n",
    "#             sources = [f'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{example[0]}\\n\\n### Input:\\n{example[1]}\\n\\n### Response:' for example in data]\n",
    "#         else:\n",
    "#             sources = [f'{example[0]}\\n\\nInput: {example[1]}\\n\\nOutput:' for example in data]\n",
    "#         targets = [f'{example[2]}{tokenizer.eos_token}' for example in data]\n",
    "\n",
    "#         data_dict = self.preprocess(sources, targets, tokenizer, generation)\n",
    "\n",
    "#         self.input_ids = data_dict[\"input_ids\"]\n",
    "#         self.labels = data_dict[\"labels\"]\n",
    "#         self.tasks = [example[-1] for example in data]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export() # type: ignore  # noqa: E702\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
